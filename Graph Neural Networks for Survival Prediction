{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61f8079",
   "metadata": {
    "papermill": {
     "duration": 0.007288,
     "end_time": "2025-05-12T18:19:02.186263",
     "exception": false,
     "start_time": "2025-05-12T18:19:02.178975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Graph Neural Networks for Survival Prediction: A Novel Biostatistical Approach to the Titanic Dataset\n",
    "\n",
    "The Titanic dataset is a classic dataset for binary classification (predicting survival: 0 or 1) and has direct relevance to biostatistics, particularly in the domain of survival analysis. Biostatistics applies statistical methods to biological and medical data, often focusing on outcomes like survival, disease progression, or treatment efficacy. Here’s why this project aligns with biostatistical goals:\n",
    "\n",
    "- Survival Analysis Context: The Titanic dataset involves predicting whether passengers survived the disaster based on features like age, sex, and passenger class. This mirrors survival analysis tasks in biostatistics, where the outcome is a binary event (e.g., survival vs. death). The dataset has been referenced in biostatistical contexts, such as by the Vanderbilt University Department of Biostatistics.\n",
    "- Population-Level Insights: By using a GNN, the project models passengers as nodes in a graph, with edges representing similarity in characteristics. This approach captures relational patterns (e.g., whether passengers with similar profiles had correlated survival outcomes), which is valuable in biostatistics for understanding population dynamics, such as in epidemiological studies or clinical trials.\n",
    "- Innovative Methodology: Traditional biostatistical models for survival analysis (e.g., logistic regression, Cox proportional hazards) treat observations as independent. The GNN’s graph-based approach introduces a novel perspective by modeling dependencies between individuals, potentially revealing insights into group-level factors affecting survival (e.g., access to lifeboats based on class or gender)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07423c32",
   "metadata": {
    "papermill": {
     "duration": 0.006655,
     "end_time": "2025-05-12T18:19:02.199501",
     "exception": false,
     "start_time": "2025-05-12T18:19:02.192846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Installing Dependencies\n",
    "Installs the <span style=\"color:orange\">torch-geometric</span> library, which is required for implementing the GCN model. This library is not pre-installed in Kaggle notebooks, so it must be installed at runtime.\n",
    "- <span style=\"color:orange\">torch-geometric</span> provides tools for graph-based deep learning, including the <span style=\"color:orange\">GCNConv</span> layer used in the model.\n",
    "\n",
    "Enables the use of advanced graph neural network techniques, which are central to the project’s unique approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d99b57b",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a",
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:02.213858Z",
     "iopub.status.busy": "2025-05-12T18:19:02.213569Z",
     "iopub.status.idle": "2025-05-12T18:19:07.677978Z",
     "shell.execute_reply": "2025-05-12T18:19:07.677081Z"
    },
    "papermill": {
     "duration": 5.47271,
     "end_time": "2025-05-12T18:19:07.679538",
     "exception": false,
     "start_time": "2025-05-12T18:19:02.206828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\r\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.16)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.19.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\r\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\r\n",
      "Successfully installed torch-geometric-2.6.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc5901",
   "metadata": {
    "papermill": {
     "duration": 0.006937,
     "end_time": "2025-05-12T18:19:07.693782",
     "exception": false,
     "start_time": "2025-05-12T18:19:07.686845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Importing Libraries\n",
    "- Data Manipulation:\n",
    "  - <span style=\"color:orange\">pandas (pd):</span> Handles the Titanic dataset as a DataFrame for loading and preprocessing.\n",
    "  - <span style=\"color:orange\">numpy (np):</span> Supports numerical operations, such as array manipulation.\n",
    "- Preprocessing:\n",
    "  - <span style=\"color:orange\">sklearn.preprocessing.StandardScaler:</span> Standardizes features to have zero mean and unit variance, crucial for distance-based graph construction.\n",
    "  - <span style=\"color:orange\">sklearn.model_selection.train_test_split:</span> Splits data into training and validation sets.\n",
    "  - <span style=\"color:orange\">sklearn.metrics.pairwise_distances:</span> Computes pairwise distances between passengers for graph construction.\n",
    "- Deep Learning:\n",
    "  - <span style=\"color:orange\">torch:</span> PyTorch library for tensor operations and neural network implementation.\n",
    "  - <span style=\"color:orange\">torch.nn.functional (F):</span> Provides activation functions (e.g., ReLU) and loss functions.\n",
    "- Graph Neural Networks:\n",
    "  - <span style=\"color:orange\">torch_geometric.data.Data:</span> Creates a graph data object for GNN processing.\n",
    "  - <span style=\"color:orange\">torch_geometric.nn.GCNConv:</span> Implements graph convolutional layers for the GCN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf7eae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:07.709558Z",
     "iopub.status.busy": "2025-05-12T18:19:07.708876Z",
     "iopub.status.idle": "2025-05-12T18:19:21.596278Z",
     "shell.execute_reply": "2025-05-12T18:19:21.595523Z"
    },
    "papermill": {
     "duration": 13.896831,
     "end_time": "2025-05-12T18:19:21.597803",
     "exception": false,
     "start_time": "2025-05-12T18:19:07.700972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08443b6a",
   "metadata": {
    "papermill": {
     "duration": 0.006147,
     "end_time": "2025-05-12T18:19:21.610824",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.604677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Loading the Dataset\n",
    "The dataset is stored in <span style=\"color:orange\">/kaggle/input/titanic/train.csv</span>, as added via Kaggle’s data interface.\n",
    "- <span style=\"color:orange\">pandas.read_csv</span> reads the CSV file into a DataFrame with 891 rows and 12 columns: <span style=\"color:orange\">PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, and Embarked.</span>\n",
    "\n",
    "The <span style=\"color:orange\">Survived</span> column is the target variable (0 = did not survive, 1 = survived), and other columns are potential features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51304b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:21.624763Z",
     "iopub.status.busy": "2025-05-12T18:19:21.624286Z",
     "iopub.status.idle": "2025-05-12T18:19:21.641829Z",
     "shell.execute_reply": "2025-05-12T18:19:21.641237Z"
    },
    "papermill": {
     "duration": 0.026094,
     "end_time": "2025-05-12T18:19:21.643222",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.617128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/titanic/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac7dd3",
   "metadata": {
    "papermill": {
     "duration": 0.007053,
     "end_time": "2025-05-12T18:19:21.657336",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.650283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Handling Missing Values\n",
    "- Embarked:\n",
    "    - <span style=\"color:orange\">Embarked</span> (port of embarkation: C, Q, S) has 2 missing values.\n",
    "    - <span style=\"color:orange\">mode()[0]</span> finds the most common value (‘S’).\n",
    "    - <span style=\"color:orange\">fillna</span> replaces missing values with ‘S’.\n",
    "- Age:\n",
    "    - <span style=\"color:orange\">Age</span> has 177 missing values (about 20% of the dataset).\n",
    "    - <span style=\"color:orange\">mean()</span> computes the average age (approximately 29.7 years).\n",
    "    - <span style=\"color:orange\">fillna</span> replaces missing values with the mean age.\n",
    "- <span style=\"color:orange\">inplace=True</span> modifies the DataFrame directly to avoid creating a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e3dcfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:21.673495Z",
     "iopub.status.busy": "2025-05-12T18:19:21.672817Z",
     "iopub.status.idle": "2025-05-12T18:19:21.685232Z",
     "shell.execute_reply": "2025-05-12T18:19:21.684284Z"
    },
    "papermill": {
     "duration": 0.022156,
     "end_time": "2025-05-12T18:19:21.686665",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.664509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "most_common_embarked = train['Embarked'].mode()[0]\n",
    "# train['Embarked'].fillna(most_common_embarked, inplace=True)\n",
    "train['Embarked'] = train['Embarked'].fillna(most_common_embarked)\n",
    "mean_age = train['Age'].mean()\n",
    "# train['Age'].fillna(mean_age, inplace=True)\n",
    "train['Age'] = train['Age'].fillna(mean_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d9906",
   "metadata": {
    "papermill": {
     "duration": 0.006503,
     "end_time": "2025-05-12T18:19:21.700030",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.693527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Encoding Categorical Variables\n",
    "- Sex:\n",
    "    - <span style=\"color:orange\">Sex</span> (male, female) is binary and mapped to 0 (male) or 1 (female) using <span style=\"color:orange\">map</span>.\n",
    "- Embarked:\n",
    "    - <span style=\"color:orange\">Embarked</span> (C, Q, S) is one-hot encoded using <span style=\"color:orange\">pd.get_dummies</span>, creating three binary columns: <span style=\"color:orange\">Embarked_C, Embarked_Q, Embarked_S</span>.\n",
    "    - The original <span style=\"color:orange\">Embarked</span> column is dropped.\n",
    "- Pclass:\n",
    "    - <span style=\"color:orange\">Pclass</span> (1, 2, 3) is one-hot encoded into <span style=\"color:orange\">Pclass_1, Pclass_2, Pclass_3</span>.\n",
    "    - The original <span style=\"color:orange\">Pclass</span> column is dropped.\n",
    "    - <span style=\"color:orange\">pd.concat</span> combines the new dummy columns with the DataFrame, and <span style=\"color:orange\">axis=1</span> ensures concatenation along columns.\n",
    "\n",
    "Machine learning models, including GNNs, require numerical inputs. One-hot encoding preserves the categorical nature of <span style=\"color:orange\">Embarked</span> and <span style=\"color:orange\">Pclass</span> without implying ordinality, while binary encoding for <span style=\"color:orange\">Sex</span> is efficient. This step prepares the data for feature standardization and graph construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c36ebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:21.714473Z",
     "iopub.status.busy": "2025-05-12T18:19:21.713873Z",
     "iopub.status.idle": "2025-05-12T18:19:21.733526Z",
     "shell.execute_reply": "2025-05-12T18:19:21.732513Z"
    },
    "papermill": {
     "duration": 0.02891,
     "end_time": "2025-05-12T18:19:21.735249",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.706339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['Sex'] = train['Sex'].map({'male': 0, 'female': 1})\n",
    "embarked_dummies = pd.get_dummies(train['Embarked'], prefix='Embarked')\n",
    "train = pd.concat([train, embarked_dummies], axis=1)\n",
    "train.drop('Embarked', axis=1, inplace=True)\n",
    "pclass_dummies = pd.get_dummies(train['Pclass'], prefix='Pclass')\n",
    "train = pd.concat([train, pclass_dummies], axis=1)\n",
    "train.drop('Pclass', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646e552",
   "metadata": {
    "papermill": {
     "duration": 0.007442,
     "end_time": "2025-05-12T18:19:21.750577",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.743135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Dropping Irrelevant Columns\n",
    "Removes columns that are not useful for modeling due to irrelevance or high missingness.\n",
    "- PassengerId: A unique identifier with no predictive value.\n",
    "- Name: Contains passenger names, which are not directly useful without feature engineering (e.g., extracting titles).\n",
    "- Ticket: Ticket numbers are mostly unique and lack clear predictive patterns.\n",
    "- Cabin: Has 687 missing values (77% missing) and is too sparse to use effectively.\n",
    "- <span style=\"color:orange\">axis=1</span> specifies column-wise dropping, and <span style=\"color:orange\">inplace=True</span> modifies the DataFrame.\n",
    "\n",
    "Simplifies the dataset to focus on predictive features (<span style=\"color:orange\">Age, SibSp, Parch, Fare, Sex, Pclass_1, Pclass_2, Pclass_3, Embarked_C, Embarked_Q, Embarked_S</span>), reducing noise and computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fee90ee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:21.765999Z",
     "iopub.status.busy": "2025-05-12T18:19:21.765420Z",
     "iopub.status.idle": "2025-05-12T18:19:21.771161Z",
     "shell.execute_reply": "2025-05-12T18:19:21.770220Z"
    },
    "papermill": {
     "duration": 0.01511,
     "end_time": "2025-05-12T18:19:21.772747",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.757637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734d1956",
   "metadata": {
    "papermill": {
     "duration": 0.007449,
     "end_time": "2025-05-12T18:19:21.787928",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.780479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Defining Features and Target\n",
    "Separates the feature matrix (<span style=\"color:orange\">X</span>) from the target variable (<span style=\"color:orange\">y</span>).\n",
    "- <span style=\"color:orange\">X</span>: Contains all columns except <span style=\"color:orange\">Survived</span>, resulting in an 891 x 11 matrix (11 features).\n",
    "- <span style=\"color:orange\">y</span>: The <span style=\"color:orange\">Survived</span> column, a binary vector (0 or 1) with 891 entries.\n",
    "- <span style=\"color:orange\">drop(axis=1)</span> removes the <span style=\"color:orange\">Survived</span> column from the DataFrame to create <span style=\"color:orange\">X</span>.\n",
    "\n",
    "Clearly defines the inputs (<span style=\"color:orange\">X</span>) and outputs (<span style=\"color:orange\">y</span>) for the machine learning model, a standard step in supervised learning tasks like survival prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "313162b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:21.804493Z",
     "iopub.status.busy": "2025-05-12T18:19:21.803888Z",
     "iopub.status.idle": "2025-05-12T18:19:21.809397Z",
     "shell.execute_reply": "2025-05-12T18:19:21.808534Z"
    },
    "papermill": {
     "duration": 0.01534,
     "end_time": "2025-05-12T18:19:21.810805",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.795465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train.drop('Survived', axis=1)\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a5186",
   "metadata": {
    "papermill": {
     "duration": 0.006747,
     "end_time": "2025-05-12T18:19:21.824330",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.817583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Standardizing Features\n",
    "Standardizes the features to have zero mean and unit variance, ensuring consistent scales for distance calculations.\n",
    "- <span style=\"color:orange\">StandardScaler</span> computes the mean and standard deviation for each feature and transforms the data using <span style=\"color:orange\">(x - mean) / std</span>.\n",
    "- <span style=\"color:orange\">fit_transform</span> fits the scaler to <span style=\"color:orange\">X</span> and transforms it in one step, producing <span style=\"color:orange\">X_scaled</span> (an 891 x 11 NumPy array).\n",
    "- Standardization is critical because features like <span style=\"color:orange\">Age</span> (range: 0-80) and <span style=\"color:orange\">Fare</span> (range: 0-512) have different scales, which could skew distance-based graph construction.\n",
    "\n",
    "Ensures that all features contribute equally to the Euclidean distance calculations used to build the graph, improving the quality of the GNN’s relational modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b6848fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:21.839208Z",
     "iopub.status.busy": "2025-05-12T18:19:21.838661Z",
     "iopub.status.idle": "2025-05-12T18:19:21.856863Z",
     "shell.execute_reply": "2025-05-12T18:19:21.856047Z"
    },
    "papermill": {
     "duration": 0.027225,
     "end_time": "2025-05-12T18:19:21.858223",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.830998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3073dd3",
   "metadata": {
    "papermill": {
     "duration": 0.005958,
     "end_time": "2025-05-12T18:19:21.870628",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.864670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. Splitting Train and Validation Sets\n",
    "Splits the dataset into 80% training and 20% validation sets to evaluate model performance.\n",
    "- <span style=\"color:orange\">train_test_split</span> splits the indices (0 to 890) into training (<span style=\"color:orange\">train_idx</span>) and validation (<span style=\"color:orange\">val_idx</span>) sets.\n",
    "- <span style=\"color:orange\">test_size=0.2</span> allocates 20% (179 samples) for validation and 80% (712 samples) for training.\n",
    "- <span style=\"color:orange\">random_state=42</span> ensures reproducibility.\n",
    "- <span style=\"color:orange\">stratify=y</span> maintains the proportion of <span style=\"color:orange\">Survived</span> classes (approximately 38% survived) in both sets.\n",
    "\n",
    "Allows the model to train on a subset of the data and evaluate generalization on unseen data, a key practice in machine learning to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4f4710f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:21.883903Z",
     "iopub.status.busy": "2025-05-12T18:19:21.883646Z",
     "iopub.status.idle": "2025-05-12T18:19:21.891490Z",
     "shell.execute_reply": "2025-05-12T18:19:21.890619Z"
    },
    "papermill": {
     "duration": 0.015838,
     "end_time": "2025-05-12T18:19:21.892697",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.876859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 712, Validation set size: 179\n"
     ]
    }
   ],
   "source": [
    "train_idx, val_idx = train_test_split(range(len(X)), test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Train set size: {len(train_idx)}, Validation set size: {len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3a9e9",
   "metadata": {
    "papermill": {
     "duration": 0.006169,
     "end_time": "2025-05-12T18:19:21.905252",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.899083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. Constructing the Graph\n",
    "Builds a graph where passengers are nodes, and edges connect each passenger to their 5 most similar peers based on feature similarity.\n",
    "- Distance Calculation:\n",
    "    - <span style=\"color:orange\">pairwise_distances(X_scaled)</span> computes Euclidean distances between all pairs of passengers, producing an 891 x 891 matrix.\n",
    "- K-Nearest Neighbors:\n",
    "    - <span style=\"color:orange\">np.argsort(distances, axis=1)</span> sorts distances for each passenger.\n",
    "    - <span style=\"color:orange\">[:, 1:k+1]</span> selects the indices of the 5 closest neighbors (excluding the passenger themselves, hence <span style=\"color:orange\">1:k+1</span>).\n",
    "    - <span style=\"color:orange\">knn_indices</span> is an 891 x 5 array of neighbor indices.\n",
    "- Edge List:\n",
    "    - The loop creates edges by pairing each passenger (<span style=\"color:orange\">i</span>) with their neighbors (<span style=\"color:orange\">j</span>).\n",
    "    - Both <span style=\"color:orange\">[i, j]</span> and <span style=\"color:orange\">[j, i]</span> are added to make the graph undirected.\n",
    "    - <span style=\"color:orange\">edges</span> is a list of edge pairs.\n",
    "- Remove Duplicates:\n",
    "    - <span style=\"color:orange\">np.unique(np.array(edges), axis=0)</span> removes duplicate edges (e.g., [i, j] and [j, i] are equivalent in an undirected graph).\n",
    "\n",
    "The graph structure is the core of the GNN, enabling the model to learn from relational patterns (e.g., passengers with similar ages or classes may have correlated survival outcomes). This relational approach is novel for the Titanic dataset and aligns with biostatistical interest in population-level interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f096b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:21.919086Z",
     "iopub.status.busy": "2025-05-12T18:19:21.918522Z",
     "iopub.status.idle": "2025-05-12T18:19:21.990787Z",
     "shell.execute_reply": "2025-05-12T18:19:21.990105Z"
    },
    "papermill": {
     "duration": 0.081024,
     "end_time": "2025-05-12T18:19:21.992431",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.911407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "distances = pairwise_distances(X_scaled)\n",
    "k = 5\n",
    "knn_indices = np.argsort(distances, axis=1)[:, 1:k+1]\n",
    "edges = []\n",
    "for i in range(len(X)):\n",
    "    for j in knn_indices[i]:\n",
    "        edges.append([i, j])\n",
    "        edges.append([j, i])\n",
    "edges = np.unique(np.array(edges), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f66868",
   "metadata": {
    "papermill": {
     "duration": 0.006422,
     "end_time": "2025-05-12T18:19:22.006108",
     "exception": false,
     "start_time": "2025-05-12T18:19:21.999686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 11. Creating the PyTorch Geometric Data Object\n",
    "Converts the data into a <span style=\"color:orange\">Data</span> object compatible with PyTorch Geometric for GNN training.\n",
    "- Node Features:\n",
    "    - <span style=\"color:orange\">x = torch.tensor(X_scaled, dtype=torch.float)</span> converts the standardized features (891 x 11) to a PyTorch tensor.\n",
    "- Edge Index:\n",
    "    - <span style=\"color:orange\">edge_index = torch.tensor(edges.T, dtype=torch.long)</span> converts the edge list to a 2 x M tensor, where M is the number of unique edges. The first row contains source nodes, and the second row contains target nodes.\n",
    "- Labels:\n",
    "    - <span style=\"color:orange\">y_torch = torch.tensor(y.values, dtype=torch.long)</span> converts the <span style=\"color:orange\">Survived</span> labels to a tensor of integers (0 or 1).\n",
    "- Masks:\n",
    "    - <span style=\"color:orange\">train_mask</span> and <span style=\"color:orange\">val_mask</span> are boolean tensors (length 891) initialized to <span style=\"color:orange\">False</span>.\n",
    "    - <span style=\"color:orange\">train_mask[train_idx] = True</span> sets <span style=\"color:orange\">True</span> for training indices.\n",
    "    - <span style=\"color:orange\">val_mask[val_idx] = True</span> sets <span style=\"color:orange\">True</span> for validation indices.\n",
    "- Data Object:\n",
    "    - <span style=\"color:orange\">Data</span> combines <span style=\"color:orange\">x, edge_index, y, train_mask,</span> and <span style=\"color:orange\">val_mask</span> into a single object for GNN processing.\n",
    "\n",
    "The <span style=\"color:orange\">Data</span> object encapsulates the graph structure and data needed for the GCN, enabling efficient graph-based learning. The masks ensure the model trains and evaluates on the correct subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d920a128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:22.076608Z",
     "iopub.status.busy": "2025-05-12T18:19:22.076321Z",
     "iopub.status.idle": "2025-05-12T18:19:22.118773Z",
     "shell.execute_reply": "2025-05-12T18:19:22.118005Z"
    },
    "papermill": {
     "duration": 0.10734,
     "end_time": "2025-05-12T18:19:22.119949",
     "exception": false,
     "start_time": "2025-05-12T18:19:22.012609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mask sum: 712, Val mask sum: 179\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(X_scaled, dtype=torch.float)\n",
    "edge_index = torch.tensor(edges.T, dtype=torch.long)\n",
    "y_torch = torch.tensor(y.values, dtype=torch.long)\n",
    "train_mask = torch.zeros(len(X), dtype=torch.bool)\n",
    "train_mask[train_idx] = True\n",
    "val_mask = torch.zeros(len(X), dtype=torch.bool)\n",
    "val_mask[val_idx] = True\n",
    "data = Data(x=x, edge_index=edge_index, y=y_torch, train_mask=train_mask, val_mask=val_mask)\n",
    "print(f\"Train mask sum: {data.train_mask.sum().item()}, Val mask sum: {data.val_mask.sum().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664c79b",
   "metadata": {
    "papermill": {
     "duration": 0.006318,
     "end_time": "2025-05-12T18:19:22.133033",
     "exception": false,
     "start_time": "2025-05-12T18:19:22.126715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 12. Defining the GCN Model\n",
    "Defines a two-layer Graph Convolutional Network to predict survival probabilities.\n",
    "- Class Definition:\n",
    "    - <span style=\"color:orange\">GCN</span> inherits from <span style=\"color:orange\">torch.nn.Module</span>, the base class for PyTorch models.\n",
    "- Initialization:\n",
    "    - <span style=\"color:orange\">input_dim</span>: Number of input features (11).\n",
    "    - <span style=\"color:orange\">hidden_dim</span>: Size of the hidden layer (16).\n",
    "    - <span style=\"color:orange\">output_dim</span>: Number of output classes (2: survive or not).\n",
    "    - <span style=\"color:orange\">conv1</span>: First GCN layer, mapping 11 features to 16 dimensions.\n",
    "    - <span style=\"color:orange\">conv2</span>: Second GCN layer, mapping 16 dimensions to 2.\n",
    "- Forward Pass:\n",
    "    - <span style=\"color:orange\">x, edge_index = data.x, data.edge_index</span>: Extracts node features and edges.\n",
    "    - <span style=\"color:orange\">conv1</span>: Applies graph convolution, aggregating information from neighboring nodes.\n",
    "    - <span style=\"color:orange\">F.relu</span>: Applies ReLU activation to introduce non-linearity.\n",
    "    - <span style=\"color:orange\">F.dropout(p=0.5, training=self.training)</span>: Randomly zeros 50% of the features during training to prevent overfitting.\n",
    "    - <span style=\"color:orange\">conv2</span>: Second graph convolution produces logits for each node.\n",
    "    - <span style=\"color:orange\">F.log_softmax(x, dim=1)</span>: Converts logits to log-probabilities for classification.\n",
    "\n",
    "The GCN leverages the graph structure to learn features that combine individual passenger data with information from similar passengers, making it suitable for capturing relational patterns in survival outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfda828f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:22.146769Z",
     "iopub.status.busy": "2025-05-12T18:19:22.146492Z",
     "iopub.status.idle": "2025-05-12T18:19:22.151720Z",
     "shell.execute_reply": "2025-05-12T18:19:22.150950Z"
    },
    "papermill": {
     "duration": 0.013678,
     "end_time": "2025-05-12T18:19:22.153089",
     "exception": false,
     "start_time": "2025-05-12T18:19:22.139411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26234e1",
   "metadata": {
    "papermill": {
     "duration": 0.007163,
     "end_time": "2025-05-12T18:19:22.166772",
     "exception": false,
     "start_time": "2025-05-12T18:19:22.159609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 13. Initializing Model and Optimizer\n",
    "Sets up the GCN model, moves it to the appropriate device (GPU or CPU), and configures the optimizer.\n",
    "- Device:\n",
    "    - <span style=\"color:orange\">device</span> checks for GPU availability (Kaggle provides GPU P100 or T4). If unavailable, it defaults to CPU.\n",
    "- Model:\n",
    "    - <span style=\"color:orange\">GCN</span> is instantiated with <span style=\"color:orange\">input_dim=11</span> (number of features), <span style=\"color:orange\">hidden_dim=16</span> (arbitrary choice for hidden layer size), and <span style=\"color:orange\">output_dim=2</span> (binary classification).\n",
    "    - <span style=\"color:orange\">to(device)</span> moves the model to the GPU or CPU.\n",
    "- Data:\n",
    "    - <span style=\"color:orange\">data.to(device)</span> moves the <span style=\"color:orange\">Data</span> object (features, edges, labels, masks) to the same device as the model.\n",
    "- Optimizer:\n",
    "    - <span style=\"color:orange\">Adam</span> optimizer is used with a learning rate (<span style=\"color:orange\">lr</span>) of 0.01 and weight decay (weight_decay) of 5e-4 for L2 regularization to prevent overfitting.\n",
    "    - <span style=\"color:orange\">model.parameters()</span> provides the model’s trainable weights.\n",
    "\n",
    "Initializes the training setup, ensuring compatibility between the model and data. The use of GPU accelerates training, and Adam is a robust optimizer for deep learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "950ed1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:22.181007Z",
     "iopub.status.busy": "2025-05-12T18:19:22.180684Z",
     "iopub.status.idle": "2025-05-12T18:19:22.422733Z",
     "shell.execute_reply": "2025-05-12T18:19:22.421856Z"
    },
    "papermill": {
     "duration": 0.251042,
     "end_time": "2025-05-12T18:19:22.424425",
     "exception": false,
     "start_time": "2025-05-12T18:19:22.173383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(input_dim=X_scaled.shape[1], hidden_dim=16, output_dim=2).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a662fa44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:22.439333Z",
     "iopub.status.busy": "2025-05-12T18:19:22.438679Z",
     "iopub.status.idle": "2025-05-12T18:19:22.442086Z",
     "shell.execute_reply": "2025-05-12T18:19:22.441555Z"
    },
    "papermill": {
     "duration": 0.01191,
     "end_time": "2025-05-12T18:19:22.443363",
     "exception": false,
     "start_time": "2025-05-12T18:19:22.431453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lists to store losses for plotting\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee9f1a3",
   "metadata": {
    "papermill": {
     "duration": 0.006561,
     "end_time": "2025-05-12T18:19:22.456492",
     "exception": false,
     "start_time": "2025-05-12T18:19:22.449931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 14. Training Loop\n",
    "Trains the GCN model for 100 epochs, updating weights to minimize the loss on the training set.\n",
    "- Loop Setup:\n",
    "    - <span style=\"color:orange\">num_epochs = 100</span>: Trains for 100 iterations over the dataset.\n",
    "- Training Mode:\n",
    "    - <span style=\"color:orange\">model.train()</span> enables training-specific behaviors like dropout.\n",
    "- Forward Pass:\n",
    "    - <span style=\"color:orange\">optimizer.zero_grad()</span> clears previous gradients.\n",
    "    - <span style=\"color:orange\">out = model(data)</span> computes log-probabilities for all nodes.\n",
    "- Loss Calculation:\n",
    "    - <span style=\"color:orange\">F.nll_loss(out[data.train_mask], data.y[data.train_mask])</span> computes the negative log-likelihood loss for training nodes only, comparing predicted log-probabilities to true labels.\n",
    "- Backpropagation:\n",
    "    - <span style=\"color:orange\">loss.backward()</span> computes gradients.\n",
    "    - <span style=\"color:orange\">optimizer.step()</span> updates model weights using Adam.\n",
    "\n",
    "The training loop optimizes the GCN to predict survival accurately, leveraging the graph structure to learn relational patterns. The use of <span style=\"color:orange\">train_mask</span> ensures only training nodes contribute to the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc09c1",
   "metadata": {
    "papermill": {
     "duration": 0.006927,
     "end_time": "2025-05-12T18:19:22.469661",
     "exception": false,
     "start_time": "2025-05-12T18:19:22.462734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 15. Validation\n",
    "Evaluates the model on the validation set after each epoch, reporting loss and accuracy.\n",
    "- Evaluation Mode:\n",
    "    - <span style=\"color:orange\">model.eval()</span> disables dropout and other training-specific behaviors.\n",
    "    - <span style=\"color:orange\">with torch.no_grad()</span> prevents gradient computation for efficiency.\n",
    "- Validation Forward Pass:\n",
    "    - <span style=\"color:orange\">val_out = model(data)</span> computes predictions for all nodes.\n",
    "- Validation Loss:\n",
    "    - <span style=\"color:orange\">F.nll_loss(val_out[data.val_mask], data.y[data.val_mask])</span> computes the loss for validation nodes.\n",
    "- Accuracy:\n",
    "    - <span style=\"color:orange\">val_out.max(dim=1)</span> returns the predicted class (0 or 1) for each node.\n",
    "    - <span style=\"color:orange\">pred[data.val_mask].eq(data.y[data.val_mask])</span> compares predictions to true labels for validation nodes.\n",
    "    - <span style=\"color:orange\">sum().item()</span> counts correct predictions.\n",
    "    - <span style=\"color:orange\">acc</span> is the proportion of correct predictions (correct / 179).\n",
    "- Logging:\n",
    "    - <span style=\"color:orange\">print</span> outputs the epoch number, training loss, validation loss, and validation accuracy.\n",
    "\n",
    "Validation metrics assess the model’s generalization to unseen data, crucial for ensuring the GNN is not overfitting. The printed metrics help monitor training progress and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b09ad6a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:22.484064Z",
     "iopub.status.busy": "2025-05-12T18:19:22.483790Z",
     "iopub.status.idle": "2025-05-12T18:19:23.951618Z",
     "shell.execute_reply": "2025-05-12T18:19:23.950594Z"
    },
    "papermill": {
     "duration": 1.477072,
     "end_time": "2025-05-12T18:19:23.953366",
     "exception": false,
     "start_time": "2025-05-12T18:19:22.476294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 1, Val Loss: 0.7200, Val Losses Length: 1, Val Append Count: 1\n",
      "Epoch 1, Train Loss: 0.7647, Val Loss: 0.7200, Val Acc: 0.5028\n",
      "Epoch 2, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 2, Val Loss: 0.6687, Val Losses Length: 2, Val Append Count: 2\n",
      "Epoch 2, Train Loss: 0.6916, Val Loss: 0.6687, Val Acc: 0.5978\n",
      "Epoch 3, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 3, Val Loss: 0.6268, Val Losses Length: 3, Val Append Count: 3\n",
      "Epoch 3, Train Loss: 0.6339, Val Loss: 0.6268, Val Acc: 0.6760\n",
      "Epoch 4, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 4, Val Loss: 0.5932, Val Losses Length: 4, Val Append Count: 4\n",
      "Epoch 4, Train Loss: 0.6168, Val Loss: 0.5932, Val Acc: 0.7151\n",
      "Epoch 5, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 5, Val Loss: 0.5656, Val Losses Length: 5, Val Append Count: 5\n",
      "Epoch 5, Train Loss: 0.5862, Val Loss: 0.5656, Val Acc: 0.7318\n",
      "Epoch 6, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 6, Val Loss: 0.5435, Val Losses Length: 6, Val Append Count: 6\n",
      "Epoch 6, Train Loss: 0.5643, Val Loss: 0.5435, Val Acc: 0.7430\n",
      "Epoch 7, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 7, Val Loss: 0.5258, Val Losses Length: 7, Val Append Count: 7\n",
      "Epoch 7, Train Loss: 0.5325, Val Loss: 0.5258, Val Acc: 0.7430\n",
      "Epoch 8, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 8, Val Loss: 0.5110, Val Losses Length: 8, Val Append Count: 8\n",
      "Epoch 8, Train Loss: 0.5269, Val Loss: 0.5110, Val Acc: 0.7486\n",
      "Epoch 9, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 9, Val Loss: 0.4986, Val Losses Length: 9, Val Append Count: 9\n",
      "Epoch 9, Train Loss: 0.5090, Val Loss: 0.4986, Val Acc: 0.7486\n",
      "Epoch 10, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 10, Val Loss: 0.4879, Val Losses Length: 10, Val Append Count: 10\n",
      "Epoch 10, Train Loss: 0.4980, Val Loss: 0.4879, Val Acc: 0.7765\n",
      "Epoch 11, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 11, Val Loss: 0.4789, Val Losses Length: 11, Val Append Count: 11\n",
      "Epoch 11, Train Loss: 0.4612, Val Loss: 0.4789, Val Acc: 0.7877\n",
      "Epoch 12, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 12, Val Loss: 0.4711, Val Losses Length: 12, Val Append Count: 12\n",
      "Epoch 12, Train Loss: 0.4671, Val Loss: 0.4711, Val Acc: 0.7877\n",
      "Epoch 13, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 13, Val Loss: 0.4644, Val Losses Length: 13, Val Append Count: 13\n",
      "Epoch 13, Train Loss: 0.4845, Val Loss: 0.4644, Val Acc: 0.7877\n",
      "Epoch 14, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 14, Val Loss: 0.4591, Val Losses Length: 14, Val Append Count: 14\n",
      "Epoch 14, Train Loss: 0.4564, Val Loss: 0.4591, Val Acc: 0.8045\n",
      "Epoch 15, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 15, Val Loss: 0.4548, Val Losses Length: 15, Val Append Count: 15\n",
      "Epoch 15, Train Loss: 0.4705, Val Loss: 0.4548, Val Acc: 0.8101\n",
      "Epoch 16, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 16, Val Loss: 0.4516, Val Losses Length: 16, Val Append Count: 16\n",
      "Epoch 16, Train Loss: 0.4485, Val Loss: 0.4516, Val Acc: 0.8101\n",
      "Epoch 17, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 17, Val Loss: 0.4494, Val Losses Length: 17, Val Append Count: 17\n",
      "Epoch 17, Train Loss: 0.4470, Val Loss: 0.4494, Val Acc: 0.8045\n",
      "Epoch 18, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 18, Val Loss: 0.4479, Val Losses Length: 18, Val Append Count: 18\n",
      "Epoch 18, Train Loss: 0.4564, Val Loss: 0.4479, Val Acc: 0.8045\n",
      "Epoch 19, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 19, Val Loss: 0.4471, Val Losses Length: 19, Val Append Count: 19\n",
      "Epoch 19, Train Loss: 0.4304, Val Loss: 0.4471, Val Acc: 0.8045\n",
      "Epoch 20, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 20, Val Loss: 0.4465, Val Losses Length: 20, Val Append Count: 20\n",
      "Epoch 20, Train Loss: 0.4462, Val Loss: 0.4465, Val Acc: 0.8101\n",
      "Epoch 21, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 21, Val Loss: 0.4462, Val Losses Length: 21, Val Append Count: 21\n",
      "Epoch 21, Train Loss: 0.4522, Val Loss: 0.4462, Val Acc: 0.8101\n",
      "Epoch 22, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 22, Val Loss: 0.4458, Val Losses Length: 22, Val Append Count: 22\n",
      "Epoch 22, Train Loss: 0.4460, Val Loss: 0.4458, Val Acc: 0.8045\n",
      "Epoch 23, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 23, Val Loss: 0.4451, Val Losses Length: 23, Val Append Count: 23\n",
      "Epoch 23, Train Loss: 0.4450, Val Loss: 0.4451, Val Acc: 0.8045\n",
      "Epoch 24, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 24, Val Loss: 0.4442, Val Losses Length: 24, Val Append Count: 24\n",
      "Epoch 24, Train Loss: 0.4381, Val Loss: 0.4442, Val Acc: 0.8045\n",
      "Epoch 25, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 25, Val Loss: 0.4429, Val Losses Length: 25, Val Append Count: 25\n",
      "Epoch 25, Train Loss: 0.4372, Val Loss: 0.4429, Val Acc: 0.8045\n",
      "Epoch 26, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 26, Val Loss: 0.4416, Val Losses Length: 26, Val Append Count: 26\n",
      "Epoch 26, Train Loss: 0.4247, Val Loss: 0.4416, Val Acc: 0.8045\n",
      "Epoch 27, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 27, Val Loss: 0.4399, Val Losses Length: 27, Val Append Count: 27\n",
      "Epoch 27, Train Loss: 0.4326, Val Loss: 0.4399, Val Acc: 0.8101\n",
      "Epoch 28, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 28, Val Loss: 0.4384, Val Losses Length: 28, Val Append Count: 28\n",
      "Epoch 28, Train Loss: 0.4422, Val Loss: 0.4384, Val Acc: 0.8101\n",
      "Epoch 29, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 29, Val Loss: 0.4369, Val Losses Length: 29, Val Append Count: 29\n",
      "Epoch 29, Train Loss: 0.4351, Val Loss: 0.4369, Val Acc: 0.8101\n",
      "Epoch 30, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 30, Val Loss: 0.4357, Val Losses Length: 30, Val Append Count: 30\n",
      "Epoch 30, Train Loss: 0.4287, Val Loss: 0.4357, Val Acc: 0.8101\n",
      "Epoch 31, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 31, Val Loss: 0.4346, Val Losses Length: 31, Val Append Count: 31\n",
      "Epoch 31, Train Loss: 0.4254, Val Loss: 0.4346, Val Acc: 0.8101\n",
      "Epoch 32, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 32, Val Loss: 0.4337, Val Losses Length: 32, Val Append Count: 32\n",
      "Epoch 32, Train Loss: 0.4201, Val Loss: 0.4337, Val Acc: 0.8045\n",
      "Epoch 33, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 33, Val Loss: 0.4329, Val Losses Length: 33, Val Append Count: 33\n",
      "Epoch 33, Train Loss: 0.4263, Val Loss: 0.4329, Val Acc: 0.7989\n",
      "Epoch 34, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 34, Val Loss: 0.4324, Val Losses Length: 34, Val Append Count: 34\n",
      "Epoch 34, Train Loss: 0.4266, Val Loss: 0.4324, Val Acc: 0.7933\n",
      "Epoch 35, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 35, Val Loss: 0.4319, Val Losses Length: 35, Val Append Count: 35\n",
      "Epoch 35, Train Loss: 0.4253, Val Loss: 0.4319, Val Acc: 0.7933\n",
      "Epoch 36, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 36, Val Loss: 0.4315, Val Losses Length: 36, Val Append Count: 36\n",
      "Epoch 36, Train Loss: 0.4191, Val Loss: 0.4315, Val Acc: 0.7989\n",
      "Epoch 37, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 37, Val Loss: 0.4314, Val Losses Length: 37, Val Append Count: 37\n",
      "Epoch 37, Train Loss: 0.4379, Val Loss: 0.4314, Val Acc: 0.7989\n",
      "Epoch 38, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 38, Val Loss: 0.4313, Val Losses Length: 38, Val Append Count: 38\n",
      "Epoch 38, Train Loss: 0.4101, Val Loss: 0.4313, Val Acc: 0.8045\n",
      "Epoch 39, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 39, Val Loss: 0.4313, Val Losses Length: 39, Val Append Count: 39\n",
      "Epoch 39, Train Loss: 0.4202, Val Loss: 0.4313, Val Acc: 0.8045\n",
      "Epoch 40, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 40, Val Loss: 0.4314, Val Losses Length: 40, Val Append Count: 40\n",
      "Epoch 40, Train Loss: 0.4234, Val Loss: 0.4314, Val Acc: 0.8045\n",
      "Epoch 41, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 41, Val Loss: 0.4317, Val Losses Length: 41, Val Append Count: 41\n",
      "Epoch 41, Train Loss: 0.4329, Val Loss: 0.4317, Val Acc: 0.8045\n",
      "Epoch 42, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 42, Val Loss: 0.4321, Val Losses Length: 42, Val Append Count: 42\n",
      "Epoch 42, Train Loss: 0.4194, Val Loss: 0.4321, Val Acc: 0.8045\n",
      "Epoch 43, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 43, Val Loss: 0.4326, Val Losses Length: 43, Val Append Count: 43\n",
      "Epoch 43, Train Loss: 0.4195, Val Loss: 0.4326, Val Acc: 0.8045\n",
      "Epoch 44, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 44, Val Loss: 0.4330, Val Losses Length: 44, Val Append Count: 44\n",
      "Epoch 44, Train Loss: 0.4219, Val Loss: 0.4330, Val Acc: 0.8045\n",
      "Epoch 45, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 45, Val Loss: 0.4335, Val Losses Length: 45, Val Append Count: 45\n",
      "Epoch 45, Train Loss: 0.4219, Val Loss: 0.4335, Val Acc: 0.8045\n",
      "Epoch 46, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 46, Val Loss: 0.4340, Val Losses Length: 46, Val Append Count: 46\n",
      "Epoch 46, Train Loss: 0.4153, Val Loss: 0.4340, Val Acc: 0.7933\n",
      "Epoch 47, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 47, Val Loss: 0.4345, Val Losses Length: 47, Val Append Count: 47\n",
      "Epoch 47, Train Loss: 0.4170, Val Loss: 0.4345, Val Acc: 0.7989\n",
      "Epoch 48, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 48, Val Loss: 0.4348, Val Losses Length: 48, Val Append Count: 48\n",
      "Epoch 48, Train Loss: 0.4158, Val Loss: 0.4348, Val Acc: 0.7989\n",
      "Epoch 49, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 49, Val Loss: 0.4349, Val Losses Length: 49, Val Append Count: 49\n",
      "Epoch 49, Train Loss: 0.4167, Val Loss: 0.4349, Val Acc: 0.7989\n",
      "Epoch 50, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 50, Val Loss: 0.4351, Val Losses Length: 50, Val Append Count: 50\n",
      "Epoch 50, Train Loss: 0.4064, Val Loss: 0.4351, Val Acc: 0.7989\n",
      "Epoch 51, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 51, Val Loss: 0.4352, Val Losses Length: 51, Val Append Count: 51\n",
      "Epoch 51, Train Loss: 0.4168, Val Loss: 0.4352, Val Acc: 0.7989\n",
      "Epoch 52, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 52, Val Loss: 0.4354, Val Losses Length: 52, Val Append Count: 52\n",
      "Epoch 52, Train Loss: 0.4070, Val Loss: 0.4354, Val Acc: 0.7989\n",
      "Epoch 53, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 53, Val Loss: 0.4357, Val Losses Length: 53, Val Append Count: 53\n",
      "Epoch 53, Train Loss: 0.4270, Val Loss: 0.4357, Val Acc: 0.8045\n",
      "Epoch 54, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 54, Val Loss: 0.4360, Val Losses Length: 54, Val Append Count: 54\n",
      "Epoch 54, Train Loss: 0.4184, Val Loss: 0.4360, Val Acc: 0.8045\n",
      "Epoch 55, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 55, Val Loss: 0.4365, Val Losses Length: 55, Val Append Count: 55\n",
      "Epoch 55, Train Loss: 0.4055, Val Loss: 0.4365, Val Acc: 0.8101\n",
      "Epoch 56, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 56, Val Loss: 0.4370, Val Losses Length: 56, Val Append Count: 56\n",
      "Epoch 56, Train Loss: 0.4223, Val Loss: 0.4370, Val Acc: 0.8045\n",
      "Epoch 57, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 57, Val Loss: 0.4375, Val Losses Length: 57, Val Append Count: 57\n",
      "Epoch 57, Train Loss: 0.4131, Val Loss: 0.4375, Val Acc: 0.8045\n",
      "Epoch 58, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 58, Val Loss: 0.4380, Val Losses Length: 58, Val Append Count: 58\n",
      "Epoch 58, Train Loss: 0.4146, Val Loss: 0.4380, Val Acc: 0.8045\n",
      "Epoch 59, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 59, Val Loss: 0.4384, Val Losses Length: 59, Val Append Count: 59\n",
      "Epoch 59, Train Loss: 0.4067, Val Loss: 0.4384, Val Acc: 0.8045\n",
      "Epoch 60, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 60, Val Loss: 0.4388, Val Losses Length: 60, Val Append Count: 60\n",
      "Epoch 60, Train Loss: 0.4051, Val Loss: 0.4388, Val Acc: 0.8045\n",
      "Epoch 61, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 61, Val Loss: 0.4391, Val Losses Length: 61, Val Append Count: 61\n",
      "Epoch 61, Train Loss: 0.4098, Val Loss: 0.4391, Val Acc: 0.8045\n",
      "Epoch 62, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 62, Val Loss: 0.4393, Val Losses Length: 62, Val Append Count: 62\n",
      "Epoch 62, Train Loss: 0.4074, Val Loss: 0.4393, Val Acc: 0.8045\n",
      "Epoch 63, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 63, Val Loss: 0.4391, Val Losses Length: 63, Val Append Count: 63\n",
      "Epoch 63, Train Loss: 0.4082, Val Loss: 0.4391, Val Acc: 0.8045\n",
      "Epoch 64, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 64, Val Loss: 0.4387, Val Losses Length: 64, Val Append Count: 64\n",
      "Epoch 64, Train Loss: 0.4149, Val Loss: 0.4387, Val Acc: 0.8045\n",
      "Epoch 65, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 65, Val Loss: 0.4383, Val Losses Length: 65, Val Append Count: 65\n",
      "Epoch 65, Train Loss: 0.4075, Val Loss: 0.4383, Val Acc: 0.8045\n",
      "Epoch 66, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 66, Val Loss: 0.4380, Val Losses Length: 66, Val Append Count: 66\n",
      "Epoch 66, Train Loss: 0.4032, Val Loss: 0.4380, Val Acc: 0.7989\n",
      "Epoch 67, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 67, Val Loss: 0.4375, Val Losses Length: 67, Val Append Count: 67\n",
      "Epoch 67, Train Loss: 0.4045, Val Loss: 0.4375, Val Acc: 0.7989\n",
      "Epoch 68, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 68, Val Loss: 0.4369, Val Losses Length: 68, Val Append Count: 68\n",
      "Epoch 68, Train Loss: 0.4104, Val Loss: 0.4369, Val Acc: 0.8045\n",
      "Epoch 69, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 69, Val Loss: 0.4365, Val Losses Length: 69, Val Append Count: 69\n",
      "Epoch 69, Train Loss: 0.3986, Val Loss: 0.4365, Val Acc: 0.8045\n",
      "Epoch 70, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 70, Val Loss: 0.4363, Val Losses Length: 70, Val Append Count: 70\n",
      "Epoch 70, Train Loss: 0.4156, Val Loss: 0.4363, Val Acc: 0.8045\n",
      "Epoch 71, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 71, Val Loss: 0.4362, Val Losses Length: 71, Val Append Count: 71\n",
      "Epoch 71, Train Loss: 0.4109, Val Loss: 0.4362, Val Acc: 0.8045\n",
      "Epoch 72, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 72, Val Loss: 0.4365, Val Losses Length: 72, Val Append Count: 72\n",
      "Epoch 72, Train Loss: 0.4003, Val Loss: 0.4365, Val Acc: 0.8045\n",
      "Epoch 73, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 73, Val Loss: 0.4368, Val Losses Length: 73, Val Append Count: 73\n",
      "Epoch 73, Train Loss: 0.4117, Val Loss: 0.4368, Val Acc: 0.8045\n",
      "Epoch 74, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 74, Val Loss: 0.4372, Val Losses Length: 74, Val Append Count: 74\n",
      "Epoch 74, Train Loss: 0.4151, Val Loss: 0.4372, Val Acc: 0.8045\n",
      "Epoch 75, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 75, Val Loss: 0.4375, Val Losses Length: 75, Val Append Count: 75\n",
      "Epoch 75, Train Loss: 0.4021, Val Loss: 0.4375, Val Acc: 0.8045\n",
      "Epoch 76, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 76, Val Loss: 0.4380, Val Losses Length: 76, Val Append Count: 76\n",
      "Epoch 76, Train Loss: 0.4067, Val Loss: 0.4380, Val Acc: 0.8045\n",
      "Epoch 77, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 77, Val Loss: 0.4386, Val Losses Length: 77, Val Append Count: 77\n",
      "Epoch 77, Train Loss: 0.4164, Val Loss: 0.4386, Val Acc: 0.8045\n",
      "Epoch 78, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 78, Val Loss: 0.4391, Val Losses Length: 78, Val Append Count: 78\n",
      "Epoch 78, Train Loss: 0.4053, Val Loss: 0.4391, Val Acc: 0.8045\n",
      "Epoch 79, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 79, Val Loss: 0.4397, Val Losses Length: 79, Val Append Count: 79\n",
      "Epoch 79, Train Loss: 0.4115, Val Loss: 0.4397, Val Acc: 0.8045\n",
      "Epoch 80, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 80, Val Loss: 0.4402, Val Losses Length: 80, Val Append Count: 80\n",
      "Epoch 80, Train Loss: 0.3968, Val Loss: 0.4402, Val Acc: 0.8045\n",
      "Epoch 81, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 81, Val Loss: 0.4407, Val Losses Length: 81, Val Append Count: 81\n",
      "Epoch 81, Train Loss: 0.4079, Val Loss: 0.4407, Val Acc: 0.8045\n",
      "Epoch 82, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 82, Val Loss: 0.4409, Val Losses Length: 82, Val Append Count: 82\n",
      "Epoch 82, Train Loss: 0.4003, Val Loss: 0.4409, Val Acc: 0.8045\n",
      "Epoch 83, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 83, Val Loss: 0.4414, Val Losses Length: 83, Val Append Count: 83\n",
      "Epoch 83, Train Loss: 0.3982, Val Loss: 0.4414, Val Acc: 0.8045\n",
      "Epoch 84, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 84, Val Loss: 0.4418, Val Losses Length: 84, Val Append Count: 84\n",
      "Epoch 84, Train Loss: 0.4042, Val Loss: 0.4418, Val Acc: 0.8045\n",
      "Epoch 85, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 85, Val Loss: 0.4419, Val Losses Length: 85, Val Append Count: 85\n",
      "Epoch 85, Train Loss: 0.4104, Val Loss: 0.4419, Val Acc: 0.8045\n",
      "Epoch 86, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 86, Val Loss: 0.4422, Val Losses Length: 86, Val Append Count: 86\n",
      "Epoch 86, Train Loss: 0.3931, Val Loss: 0.4422, Val Acc: 0.8045\n",
      "Epoch 87, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 87, Val Loss: 0.4424, Val Losses Length: 87, Val Append Count: 87\n",
      "Epoch 87, Train Loss: 0.4103, Val Loss: 0.4424, Val Acc: 0.8045\n",
      "Epoch 88, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 88, Val Loss: 0.4428, Val Losses Length: 88, Val Append Count: 88\n",
      "Epoch 88, Train Loss: 0.4088, Val Loss: 0.4428, Val Acc: 0.8045\n",
      "Epoch 89, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 89, Val Loss: 0.4428, Val Losses Length: 89, Val Append Count: 89\n",
      "Epoch 89, Train Loss: 0.4063, Val Loss: 0.4428, Val Acc: 0.8045\n",
      "Epoch 90, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 90, Val Loss: 0.4425, Val Losses Length: 90, Val Append Count: 90\n",
      "Epoch 90, Train Loss: 0.3955, Val Loss: 0.4425, Val Acc: 0.8045\n",
      "Epoch 91, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 91, Val Loss: 0.4420, Val Losses Length: 91, Val Append Count: 91\n",
      "Epoch 91, Train Loss: 0.4010, Val Loss: 0.4420, Val Acc: 0.8045\n",
      "Epoch 92, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 92, Val Loss: 0.4412, Val Losses Length: 92, Val Append Count: 92\n",
      "Epoch 92, Train Loss: 0.4074, Val Loss: 0.4412, Val Acc: 0.8045\n",
      "Epoch 93, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 93, Val Loss: 0.4404, Val Losses Length: 93, Val Append Count: 93\n",
      "Epoch 93, Train Loss: 0.4064, Val Loss: 0.4404, Val Acc: 0.8045\n",
      "Epoch 94, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 94, Val Loss: 0.4396, Val Losses Length: 94, Val Append Count: 94\n",
      "Epoch 94, Train Loss: 0.4054, Val Loss: 0.4396, Val Acc: 0.8045\n",
      "Epoch 95, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 95, Val Loss: 0.4389, Val Losses Length: 95, Val Append Count: 95\n",
      "Epoch 95, Train Loss: 0.4179, Val Loss: 0.4389, Val Acc: 0.8045\n",
      "Epoch 96, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 96, Val Loss: 0.4384, Val Losses Length: 96, Val Append Count: 96\n",
      "Epoch 96, Train Loss: 0.4004, Val Loss: 0.4384, Val Acc: 0.8045\n",
      "Epoch 97, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 97, Val Loss: 0.4378, Val Losses Length: 97, Val Append Count: 97\n",
      "Epoch 97, Train Loss: 0.4027, Val Loss: 0.4378, Val Acc: 0.8045\n",
      "Epoch 98, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 98, Val Loss: 0.4373, Val Losses Length: 98, Val Append Count: 98\n",
      "Epoch 98, Train Loss: 0.4007, Val Loss: 0.4373, Val Acc: 0.8045\n",
      "Epoch 99, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 99, Val Loss: 0.4370, Val Losses Length: 99, Val Append Count: 99\n",
      "Epoch 99, Train Loss: 0.4016, Val Loss: 0.4370, Val Acc: 0.8045\n",
      "Epoch 100, val_out shape: torch.Size([891, 2]), val_mask shape: torch.Size([891]), y shape: torch.Size([891])\n",
      "Epoch 100, Val Loss: 0.4368, Val Losses Length: 100, Val Append Count: 100\n",
      "Epoch 100, Train Loss: 0.4037, Val Loss: 0.4368, Val Acc: 0.8045\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "val_block_count = 0  # Track validation block executions\n",
    "val_append_count = 0  # Track successful val_losses appends\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    try:\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    except Exception as e:\n",
    "        print(f\"Training error in epoch {epoch+1}: {str(e)}\")\n",
    "        continue\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if data.val_mask.sum() == 0:\n",
    "            raise ValueError(\"Validation mask is empty. Check train_test_split or val_mask initialization.\")\n",
    "        try:\n",
    "            val_out = model(data)\n",
    "            print(f\"Epoch {epoch+1}, val_out shape: {val_out.shape}, val_mask shape: {data.val_mask.shape}, y shape: {data.y.shape}\")\n",
    "            if val_out[data.val_mask].shape[0] != data.y[data.val_mask].shape[0]:\n",
    "                raise ValueError(f\"Shape mismatch: val_out[data.val_mask] {val_out[data.val_mask].shape}, y[data.val_mask] {data.y[data.val_mask].shape}\")\n",
    "            val_loss = F.nll_loss(val_out[data.val_mask], data.y[data.val_mask])\n",
    "            val_losses.append(val_loss.item())\n",
    "            val_append_count += 1\n",
    "            val_block_count += 1\n",
    "            print(f\"Epoch {epoch+1}, Val Loss: {val_loss.item():.4f}, Val Losses Length: {len(val_losses)}, Val Append Count: {val_append_count}\")\n",
    "            _, pred = val_out.max(dim=1)\n",
    "            correct = pred[data.val_mask].eq(data.y[data.val_mask]).sum().item()\n",
    "            acc = correct / data.val_mask.sum().item() if data.val_mask.sum().item() > 0 else 0.0\n",
    "            print(f\"Epoch {epoch+1}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val Acc: {acc:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Validation error in epoch {epoch+1}: {str(e)}\")\n",
    "            val_block_count += 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f442c52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:23.970333Z",
     "iopub.status.busy": "2025-05-12T18:19:23.969967Z",
     "iopub.status.idle": "2025-05-12T18:19:23.974672Z",
     "shell.execute_reply": "2025-05-12T18:19:23.973831Z"
    },
    "papermill": {
     "duration": 0.014374,
     "end_time": "2025-05-12T18:19:23.975886",
     "exception": false,
     "start_time": "2025-05-12T18:19:23.961512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation block executed 100 times\n",
      "Length of train_losses: 100, Length of val_losses: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation block executed {val_block_count} times\")\n",
    "print(f\"Length of train_losses: {len(train_losses)}, Length of val_losses: {len(val_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ea142",
   "metadata": {
    "papermill": {
     "duration": 0.007423,
     "end_time": "2025-05-12T18:19:23.991059",
     "exception": false,
     "start_time": "2025-05-12T18:19:23.983636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "| Part | Purpose | Key Functionality | Biostatistical/ML Relevance |\n",
    "|---|---|---|---|\n",
    "| Install Dependencies | Installs torch-geometric | Runs `!pip install` | Enables GNN implementation |\n",
    "| Import Libraries | Loads required tools | Imports pandas, torch, etc. | Supports data processing and modeling |\n",
    "| Load Dataset | Reads train.csv | Uses `pd.read_csv` | Provides raw data for analysis |\n",
    "| Handle Missing Values | Imputes missing Age, Embarked | Fills with mean/mode | Ensures complete data for modeling |\n",
    "| Encode Categorical Variables | Converts Sex, Embarked, Pclass to numerical | Uses mapping and one-hot encoding | Prepares data for ML |\n",
    "| Drop Irrelevant Columns | Removes PassengerId, Name, etc. | Uses `drop` | Reduces noise |\n",
    "| Define Features/Target | Separates X and y | Uses `drop` | Sets up supervised learning |\n",
    "| Standardize Features | Scales features | Uses StandardScaler | Ensures fair distance calculations |\n",
    "| Split Train/Validation | Creates training and validation sets | Uses `train_test_split` | Enables model evaluation |\n",
    "| Construct Graph | Builds k-NN graph | Computes distances, creates edges | Enables relational modeling |\n",
    "| Create Data Object | Prepares data for GNN | Uses Data | Integrates features, edges, labels |\n",
    "| Define GCN Model | Specifies GCN architecture | Uses GCNConv layers | Implements graph-based learning |\n",
    "| Initialize Model/Optimizer | Sets up training | Moves to GPU, configures Adam | Prepares for optimization |\n",
    "| Training Loop | Trains the model | Computes loss, updates weights | Optimizes survival predictions |\n",
    "| Validation | Evaluates on validation set | Computes loss, accuracy | Assesses generalization |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efbfb24",
   "metadata": {
    "papermill": {
     "duration": 0.007195,
     "end_time": "2025-05-12T18:19:24.005788",
     "exception": false,
     "start_time": "2025-05-12T18:19:23.998593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 16.Save the state dictionary and Save the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbe9529a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:24.022095Z",
     "iopub.status.busy": "2025-05-12T18:19:24.021515Z",
     "iopub.status.idle": "2025-05-12T18:19:24.028460Z",
     "shell.execute_reply": "2025-05-12T18:19:24.027777Z"
    },
    "papermill": {
     "duration": 0.016437,
     "end_time": "2025-05-12T18:19:24.029710",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.013273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/kaggle/working/titanic_gcn_model.pth')\n",
    "torch.save(model, '/kaggle/working/titanic_gcn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5571267",
   "metadata": {
    "papermill": {
     "duration": 0.007121,
     "end_time": "2025-05-12T18:19:24.044467",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.037346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 17. Visualization and Metrics Setup\n",
    "- Functionality:\n",
    "    - <span style=\"color:orange\">model.eval()</span>: Switches the model to evaluation mode, disabling dropout and batch normalization layers used during training to ensure consistent predictions.\n",
    "    - <span style=\"color:orange\">with torch.no_grad()</span>: Disables gradient computation to save memory and speed up inference, as no backpropagation is needed for evaluation.\n",
    "    - <span style=\"color:orange\">val_out = model(data)</span>: Runs the model on the entire dataset to get output logits (raw scores) for all nodes in the graph.\n",
    "    - <span style=\"color:orange\">_, pred = val_out.max(dim=1)</span>: Extracts predicted classes by selecting the index (0 or 1) with the highest logit score along dimension 1 (class dimension).\n",
    "    - <span style=\"color:orange\">val_pred = pred[data.val_mask].cpu().numpy()</span>: Filters predictions for the validation set (using val_mask), moves them to CPU, and converts to a NumPy array for compatibility with scikit-learn metrics.\n",
    "    - <span style=\"color:orange\">val_true = data.y[data.val_mask].cpu().numpy()</span>: Gets the true labels for the validation set, similarly converted to NumPy.\n",
    "    - <span style=\"color:orange\">val_probs = torch.softmax(val_out[data.val_mask], dim=1)[:, 1].cpu().numpy()</span>: Applies softmax to convert validation logits to probabilities, selects the probability for class 1 (Survived), and converts to NumPy.\n",
    "<br>\n",
    "<br>\n",
    "- This block prepares the data needed for performance metrics and visualizations. It generates predictions (<span style=\"color:orange\">val_pred</span>), true labels (<span style=\"color:orange\">val_true</span>), and probabilities (<span style=\"color:orange\">val_probs</span>) for the validation set, which are used in subsequent metrics (F1 score, confusion matrix, ROC curve).\n",
    "- For the Titanic dataset, where the goal is to predict survival (binary classification), these outputs allow you to evaluate how well the GCN model distinguishes between \"Survived\" (1) and \"Not Survived\" (0).\n",
    "- The use of <span style=\"color:orange\">val_mask</span> ensures only the validation subset (20% of the data, as defined in your train-test split) is evaluated, avoiding data leakage and providing an unbiased estimate of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd599001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:24.060355Z",
     "iopub.status.busy": "2025-05-12T18:19:24.060064Z",
     "iopub.status.idle": "2025-05-12T18:19:24.071326Z",
     "shell.execute_reply": "2025-05-12T18:19:24.070418Z"
    },
    "papermill": {
     "duration": 0.020721,
     "end_time": "2025-05-12T18:19:24.072668",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.051947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_true shape: (179,), val_pred shape: (179,)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_out = model(data)\n",
    "    _, pred = val_out.max(dim=1)\n",
    "    val_pred = pred[data.val_mask].cpu().numpy()\n",
    "    val_true = data.y[data.val_mask].cpu().numpy()\n",
    "    val_probs = torch.softmax(val_out[data.val_mask], dim=1)[:, 1].cpu().numpy()\n",
    "    print(f\"val_true shape: {val_true.shape}, val_pred shape: {val_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480f7b7",
   "metadata": {
    "papermill": {
     "duration": 0.007021,
     "end_time": "2025-05-12T18:19:24.087532",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.080511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 18. F1 Score\n",
    "- <span style=\"color:orange\">f1_score(val_true, val_pred)</span>: Computes the F1 score using scikit-learn, which is the harmonic mean of precision and recall, defined as: F1 = 2 * (precision + recall) / (precision * recall)\n",
    "- <span style=\"color:orange\">val_true</span>: True validation labels (0 or 1).\n",
    "- <span style=\"color:orange\">val_pred</span>: Predicted validation labels (0 or 1).\n",
    "- <span style=\"color:orange\">print(f'Validation F1 Score: {f1:.4f}')</span>: Outputs the F1 score to the console, formatted to 4 decimal places.\n",
    "\n",
    "The F1 score is particularly relevant for the Titanic dataset, which may have class imbalance (more passengers did not survive than survived). Unlike accuracy, F1 balances precision (correct positive predictions) and recall (capturing all positive cases), making it robust for evaluating performance on minority classes (e.g., survivors).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41b4d21e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:24.103634Z",
     "iopub.status.busy": "2025-05-12T18:19:24.102943Z",
     "iopub.status.idle": "2025-05-12T18:19:24.110732Z",
     "shell.execute_reply": "2025-05-12T18:19:24.110013Z"
    },
    "papermill": {
     "duration": 0.017493,
     "end_time": "2025-05-12T18:19:24.111922",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.094429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score: 0.7059\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(val_true, val_pred)\n",
    "print(f'Validation F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50369c5e",
   "metadata": {
    "papermill": {
     "duration": 0.006798,
     "end_time": "2025-05-12T18:19:24.125584",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.118786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 19. Confusion Matrix\n",
    "- Functionality:\n",
    "    - <span style=\"color:orange\">confusion_matrix(val_true, val_pred)</span>: Computes a 2x2 matrix where rows represent true labels and columns represent predicted labels. For binary classification:\n",
    "        - <span style=\"color:orange\">cm[0,0]</span>: True Negatives (correctly predicted Not Survived).\n",
    "        - <span style=\"color:orange\">cm[0,1]</span>: False Positives (incorrectly predicted Survived).\n",
    "        - <span style=\"color:orange\">cm[1,0]</span>: False Negatives (incorrectly predicted Not Survived).\n",
    "        - <span style=\"color:orange\">cm[1,1]</span>: True Positives (correctly predicted Survived).\n",
    "    - <span style=\"color:orange\">plt.figure(figsize=(8, 6))</span>: Creates a plot with dimensions 8x6 inches.\n",
    "    - <span style=\"color:orange\">sns.heatmap(...)</span>: Uses seaborn to plot the confusion matrix as a heatmap:\n",
    "        - <span style=\"color:orange\">annot=True</span>: Displays the count in each cell.\n",
    "        - <span style=\"color:orange\">fmt='d'</span>: Formats numbers as integers.\n",
    "        - <span style=\"color:orange\">cmap='Blues'</span>: Uses a blue color scheme for visual clarity.\n",
    "        - <span style=\"color:orange\">xticklabels/yticklabels</span>: Labels axes as \"Not Survived\" and \"Survived\" for interpretability.\n",
    "    - <span style=\"color:orange\">plt.title, plt.xlabel, plt.ylabel</span>: Sets the title and axis labels.\n",
    "    - <span style=\"color:orange\">plt.savefig('/kaggle/working/confusion_matrix.png')</span>: Saves the plot to Kaggle’s output directory.\n",
    "    - <span style=\"color:orange\">plt.close()</span>: Closes the plot to free memory and prevent display in Kaggle (non-interactive environment).\n",
    "<br><br>\n",
    "- The confusion matrix directly shows the model’s classification errors, which is critical for biostatistics tasks like survival prediction. For example, false negatives (failing to predict survival) could be more costly than false positives in a real-world context.\n",
    "- For the Titanic dataset, it helps you see if the model is biased toward predicting \"Not Survived\" due to class imbalance, allowing you to assess whether it’s capturing the minority class (Survived) effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e420f17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:24.140899Z",
     "iopub.status.busy": "2025-05-12T18:19:24.140274Z",
     "iopub.status.idle": "2025-05-12T18:19:24.362254Z",
     "shell.execute_reply": "2025-05-12T18:19:24.361335Z"
    },
    "papermill": {
     "duration": 0.231068,
     "end_time": "2025-05-12T18:19:24.363767",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.132699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[102   8]\n",
      " [ 27  42]]\n",
      "Confusion matrix saved successfully at /kaggle/working/confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cm = confusion_matrix(val_true, val_pred)\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Survived', 'Survived'], yticklabels=['Not Survived', 'Survived'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig('/kaggle/working/confusion_matrix.png')\n",
    "    plt.close()\n",
    "    if os.path.exists('/kaggle/working/confusion_matrix.png'):\n",
    "        print(\"Confusion matrix saved successfully at /kaggle/working/confusion_matrix.png\")\n",
    "    else:\n",
    "        print(\"Failed to save confusion matrix\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in confusion matrix plotting: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffbf9e",
   "metadata": {
    "papermill": {
     "duration": 0.007833,
     "end_time": "2025-05-12T18:19:24.380315",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.372482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 20. Training and Validation Loss Curves\n",
    "- Functionality:\n",
    "    - <span style=\"color:orange\">plt.figure(figsize=(10, 6))</span>: Creates a plot with dimensions 10x6 inches.\n",
    "    - <span style=\"color:orange\">plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')</span>: Plots the training loss (train_losses, collected during the training loop) against epoch numbers (1 to 100).\n",
    "    - <span style=\"color:orange\">plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')</span>: Plots the validation loss (<span style=\"color:orange\">val_losses</span>, collected during the training loop) against epochs.\n",
    "    - <span style=\"color:orange\">plt.title, plt.xlabel, plt.ylabel</span>: Sets the title and axis labels.\n",
    "    - <span style=\"color:orange\">plt.legend()</span>: Adds a legend to distinguish training and validation curves.\n",
    "    - <span style=\"color:orange\">plt.grid(True)</span>: Adds a grid for better readability.\n",
    "    - <span style=\"color:orange\">plt.savefig('/kaggle/working/loss_curves.png')</span>: Saves the plot to Kaggle’s output directory.\n",
    "    - <span style=\"color:orange\">plt.close()</span>: Closes the plot to free memory.\n",
    "<br><br>\n",
    "- Loss curves show how the model’s error (negative log-likelihood loss in your case) decreases over time for both training and validation sets. This is crucial for diagnosing model behavior:\n",
    "    - If training loss decreases but validation loss plateaus or increases, the model is overfitting.\n",
    "    - If both losses are high, the model is underfitting.\n",
    "- For the Titanic dataset, this helps you determine if the GCN is learning meaningful patterns in the graph structure or if it’s memorizing the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "154aca84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:24.396916Z",
     "iopub.status.busy": "2025-05-12T18:19:24.396617Z",
     "iopub.status.idle": "2025-05-12T18:19:24.569898Z",
     "shell.execute_reply": "2025-05-12T18:19:24.568882Z"
    },
    "papermill": {
     "duration": 0.183604,
     "end_time": "2025-05-12T18:19:24.571537",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.387933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss curves saved successfully at /kaggle/working/loss_curves.png, Size: 50927 bytes\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('/kaggle/working/loss_curves.png')\n",
    "    plt.close()\n",
    "    if os.path.exists('/kaggle/working/loss_curves.png'):\n",
    "        print(f\"Loss curves saved successfully at /kaggle/working/loss_curves.png, Size: {os.path.getsize('/kaggle/working/loss_curves.png')} bytes\")\n",
    "    else:\n",
    "        print(\"Failed to save loss curves\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in loss curve plotting: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ea0ac",
   "metadata": {
    "papermill": {
     "duration": 0.007489,
     "end_time": "2025-05-12T18:19:24.587905",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.580416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 21. ROC Curve\n",
    "- Functionality:\n",
    "    - <span style=\"color:orange\">roc_curve(val_true, val_probs)</span>: Computes the Receiver Operating Characteristic (ROC) curve, returning:\n",
    "        - <span style=\"color:orange\">fpr</span>: False Positive Rate (FPR = False Positives / (False Positives + True Negatives))\n",
    "        - <span style=\"color:orange\">tpr</span>: True Positive Rate (TPR = True Positives / (True Positives + False Negatives), also called recall).\n",
    "    - <span style=\"color:orange\">_</span>: Thresholds, ignored here.\n",
    "    - <span style=\"color:orange\">val_probs</span>: Probabilities for class 1 (Survived), used to evaluate performance at different classification thresholds.\n",
    "    - <span style=\"color:orange\">roc_auc = auc(fpr, tpr)</span>: Computes the Area Under the Curve (AUC) using the trapezoidal rule, quantifying the ROC curve’s quality.\n",
    "    - <span style=\"color:orange\">plt.figure(figsize=(8, 6))</span>: Creates a plot with dimensions 8x6 inches.\n",
    "    - <span style=\"color:orange\">plt.plot(fpr, tpr, ...)</span>: Plots the ROC curve with:\n",
    "        - <span style=\"color:orange\">color='darkorange'</span>: Orange color for visibility.\n",
    "        - <span style=\"color:orange\">lw=2</span>: Line width of 2.\n",
    "        - <span style=\"color:orange\">label=f'ROC curve (AUC = {roc_auc:.2f})'</span>: Labels the curve with the AUC value.\n",
    "    - <span style=\"color:orange\">plt.plot([0, 1], [0, 1], ...)</span>: Plots a diagonal dashed line (random classifier baseline, AUC = 0.5).\n",
    "    - <span style=\"color:orange\">plt.xlim, plt.ylim</span>: Sets axis limits for clarity.\n",
    "    - <span style=\"color:orange\">plt.xlabel, plt.ylabel, plt.title</span>: Sets axis labels and title.\n",
    "    - <span style=\"color:orange\">plt.legend(loc='lower right')</span>: Places the legend in the lower-right corner.\n",
    "    - <span style=\"color:orange\">plt.grid(True)</span>: Adds a grid.\n",
    "    - <span style=\"color:orange\">plt.savefig('/kaggle/working/roc_curve.png')</span>: Saves the plot to Kaggle’s output directory.\n",
    "    - <span style=\"color:orange\">plt.close()</span>: Closes the plot.\n",
    "<br><br>\n",
    "- The ROC curve evaluates the model’s ability to distinguish between classes (Survived vs. Not Survived) across all possible thresholds. A higher AUC (closer to 1) indicates better performance; AUC = 0.5 suggests random guessing.\n",
    "- For the Titanic dataset, where survival prediction involves imbalanced classes, the ROC curve helps assess how well the model balances sensitivity (detecting survivors) and specificity (avoiding false positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbf096ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:19:24.604570Z",
     "iopub.status.busy": "2025-05-12T18:19:24.603974Z",
     "iopub.status.idle": "2025-05-12T18:19:24.751285Z",
     "shell.execute_reply": "2025-05-12T18:19:24.750169Z"
    },
    "papermill": {
     "duration": 0.157096,
     "end_time": "2025-05-12T18:19:24.752615",
     "exception": false,
     "start_time": "2025-05-12T18:19:24.595519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC curve saved successfully at /kaggle/working/roc_curve.png, Size: 38572 bytes\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    fpr, tpr, _ = roc_curve(val_true, val_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('/kaggle/working/roc_curve.png')\n",
    "    plt.close()\n",
    "    if os.path.exists('/kaggle/working/roc_curve.png'):\n",
    "        print(f\"ROC curve saved successfully at /kaggle/working/roc_curve.png, Size: {os.path.getsize('/kaggle/working/roc_curve.png')} bytes\")\n",
    "    else:\n",
    "        print(\"Failed to save ROC curve\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in ROC curve plotting: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.285706,
   "end_time": "2025-05-12T18:19:28.103339",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-12T18:18:57.817633",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
